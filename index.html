<!DOCTYPE HTML>
<!--
	Alpha by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Home - SAMSeg</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="icon" type="image/png" href="images/favicon/favicon-16x16.png" sizes="16x16">
		<link rel="icon" type="image/png" href="images/favicon/favicon-32x32.png" sizes="32x32">
		<link rel="icon" type="image/png" href="images/favicon/favicon.ico" sizes="any">
	</head>
	<body class="landing is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header" class="alt">
					<h1><a class="icon solid fa-brain" href="index.html"> SAMSeg</a> Honour's Research Project</h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html" class="button icon solid fa-home">Home</a></li>
							<li>
								<a href="#" class="icon solid fa-angle-down button">Projects</a>
								<ul>
									<li><a href="u-sam.html">U-SAM</a></li>
									<li><a href="lora.html">SAM-LoRA</a></li>
								</ul>
							</li>
						</ul>
					</nav>
				</header>

			<!-- Banner -->
				<section id="banner">
					<img style="display: block; margin: auto; width: 100%; max-width: 1050px; min-width: 450px;" src="images/decoration/title.png" alt="SAMSeg Title"/>
				</section>

			<!-- Main -->
				<section id="main" class="container">

					<section class="box special" style="margin: 0">
						<header id="overview" class="major" style="scroll-margin-top: 80px">
							<!-- <h2>&#10022; Overview &#10022;</h2> -->
							<h2> Overview </h2>
							
							<p>The <em>Segment Anything Model (SAM)</em> is a state-of-the-art, promptable deep
								learning model that excels in 2D natural image segmentation. However,
								medical imaging, especially brain tumour segmentation, presents unique
								challenges due to the complexity of tumour boundaries and the multidimensionality of data.
								This project aims to enhance SAM's capability for
								brain tumour segmentation through Parameter-Efficient Fine-Tuning
								(PEFT) on the BraTS Intracranial Meningioma 2023 dataset. In addition,
								we introduce two framework modifications to augment SAM's performance:
								<strong>U-SAM</strong> and <strong>SAM-LoRA</strong>.</p>
						</header>
					</section>

					<div class="parallax" style="background-image: url(images/decoration/decoration1.jpg);"></div>

					<section class="box special" style="margin: 0">
						<div class="row.aln-middle">
							<section>
								<span class="icon solid major fa-clipboard-list accent2"></span>
								<!-- <h2>&#10022; Benchmarking: Vanilla and PEFT-SAM &#10022;</h2> -->
								<h2> Benchmarking: Vanilla and PEFT-SAM </h2>

								<p>Our project began with establishing a strong foundation using the baseline model, Vanilla SAM, 
									which delivered commendable results for tumour segmentation. Starting with <strong>84.1%</strong> accuracy, 
									Vanilla SAM demonstrated its capability in identifying tumour regions effectively.</p>

								<span class="image">
									<img style="width: 100%; height: auto; max-height: 100px;" src="images/PEFT/samples.png" alt="Scan Type Visual">
								</span>
								
								<p>A lot of our design decisions were justified by existing efforts in the Medical SAM community,
									such as using bounding boxes and slicing the 3D MRI volume into 2D slices to be processed by SAM.
									We also performed various preprocessing steps standard in medical imaging, such as Z-Score normalisation
									and rescaling, to ensure standardized intensities across samples, and especially across the four scan-types per sample,
									as seen above. These four scan-types are the same anatomical regions captured through different MRI protocols,
									each offering unique tissue contrasts crucial for enhancing the segmentation process. This comprehensive imaging approach
									allows the model to extract detailed features from various perspectives, improving tumour delineation and overall segmentation accuracy.
								</p>
									
								<p>
									<span class="image left">
										<img style="width: 30em; height: auto;" src="images/PEFT/classes.png" alt="Class Conversion Visual">
									</span>
									One of the notable preprocessing steps we performed was converting the dataset's original four-class system
									to a simpler binary tumour segmentation. In this new system, each pixel is either classified as part of the
									tumour or not in the model's prediction. This approach was chosen because the complexities involved in multi-class
									tumour segmentation were outside the scope of this project due to the medical nuances. By simplifying the classification,
									we were able to streamline the segmentation process with SAM, focusing exclusively on tumour presence versus absence,
									which aligned with our project goals.
								</p>
							
								<p>For our PEFT-SAM (Parameter-Efficient Fine-Tuning) approach, PEFT refers to training only the mask decoder
									while freezing all other SAM modules, a common strategy from our research. To train PEFT-SAM on the BraTS data,
									we used a Weighted Combination of Mean Squared Error and Cross Entropy loss functions, along with the Adam Optimizer.
									Additionally, we applied Optuna hyperparameter tuning to optimize the number of epochs, samples per epoch, and
									other parameters, alongside an exponentially decaying learning rate schedule.
									Our training allowed us to expose SAM to the intricacies of the brain MRIs and the complexity of the tumours,
									ultimately improving the accuracy to <strong>87.7%</strong> â€” a notable increase of <strong>3.6%</strong> from our Vanilla SAM.
									The graph below shows the progression of our PEFT-SAM training across 125 epochs, illustrating the relationship between Training Loss (blue line),
									Validation Loss (orange bars), and Validation Dice (green markers), which is the performance on the Validation Set:</p>

								<img style="display: block; margin: auto; margin-bottom: 30px; width: 100%; max-width: 750px; height: auto;" src="images/PEFT/peft_training.png" alt="PEFT-SAM Training Progress"/>

								<p>The below grid visualises the progression from Vanilla SAM to our best version of PEFT-SAM across six sample cases.
									Each animation represents the axial slice with the largest cross-sectional area of the tumour, highlighting how our training has
									impacted SAM's predictions. Green indicates true positives, red marks false positives, and blue shows false negatives.
									While further fine-tuning of PEFT-SAM could have continued to reduce false negatives and false positives, our focus shifted
									toward framework modifications for this project. It is evident that while the predictions are still not at the clinical-grade
									accuracy needed, our PEFT-SAM training was successful in substantially reducing the false positives, which were a significant
									issue in Vanilla SAM's predictions.</p>

								<div class="box alt" style="display: block; margin: auto; width: 90%">
									<div class="row gtr-50 gtr-uniform">
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01275-000.gif" alt=""></span></div>
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01278-000.gif" alt=""></span></div>
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01292-000.gif" alt=""></span></div>
										<!-- Commented a few out to shorten the page. You can uncomment them if needed -->
										<!-- <div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01307-000.gif" alt=""></span></div> -->
										<!-- <div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01312-000.gif" alt=""></span></div> -->
										<!-- <div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01327-000.gif" alt=""></span></div> -->
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01333-000.gif" alt=""></span></div>
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01350-000.gif" alt=""></span></div>
										<div class="col-4"><span class="image fit"><img src="images/PEFT/BraTS-MEN-01417-000.gif" alt=""></span></div>
									</div>
								</div>

								<p  style="margin-top: 30px">
									A comparison of the final 3D masks generated by our PEFT model and Vanilla SAM is shown below.
									The green regions represent the ground truth masks while model predictions are shown in red.
								</p>

								<div class="box alt" style="display: block; margin: auto; width: 90%">
									<div class="row gtr-50 gtr-uniform">
										<div class="col-6"><span class="image fit"><img src="images/PEFT/sam_vanilla_solid_3d.png" alt=""></span></div>
										<div class="col-6"><span class="image fit"><img src="images/PEFT/sam_peft_solid_3d.png" alt=""></span></div>	
									</div>
								</div>

								<p style="margin-top: 30px; margin-bottom: 0px">
									PEFT-SAM builds upon the strong foundation laid by Vanilla SAM, focusing on the key challenge of tumour segmentation and refining
									the model's interaction with prompts. This approach provided a flexible yet precise method, setting the stage for more complex architectural
									modifications with our proposed models, <strong>U-SAM</strong> and <strong>LoRA</strong>. PEFT-SAM, along with Vanilla SAM, will serve as the baseline for comparison
									against these modified models.</p>
								
							</section>
						</div>
					</section>

					<div class="parallax" style="background-image: url(images/decoration/decoration1.jpg);"></div>

					<section class="box special features" style="margin: 0">
						<div class="features-row">
							<section>
								<span class="icon solid major fa-brain accent4"></span>
								<h3>&#10023; <strong>U-SAM</strong> &#10023;</h3>
								<p>A hybrid model that integrates SAM with U-Net's superior 3D spatial capabilities for improved tumour boundary precision.</p>
								<a href="u-sam.html" class="button primary icon solid fa-book">Learn More</a>
							</section>
							<section>
								<span class="icon solid major fa-brain accent5"></span>
								<h3>&#10023; <strong>SAM-LoRA</strong> &#10023;</h3>
								<p>An investigation on applying LoRA to SAM's image encoder affects segmentation accuracy.</p>
								<a href="lora.html" class="button primary icon solid fa-book">Learn More</a>
							</section>
						</div>
					</section>


					<section class="box special features"  style="margin-top: 4rem;">
						<div class="features-row">
							<section style="width: 45%; display: inline-block; margin: 0 auto;">
								<span class="icon solid major fa-file accent5"></span>
								<h2>&#10022; <strong>Deliverables</strong> &#10022;</h2>
							</section>
							<section style="min-width: 55%;">
								<ul class="actions special">
									<li><a target="_blank" href="deliverables/SAMSeg - Project Proposal - CHKTAP011 and WLLCAS004.pdf" class="button icon solid fa-download">Project Proposal</a></li>
									<li><a target="_blank" href="deliverables/SAMSeg - Poster - CHKTAP011 and WLLCAS004.pdf" class="button icon solid fa-download">Poster</a></li>
								</ul>

								<ul class="actions special">
									<li class="del dropdown">
										<p><strong>U-SAM</strong></p>
										<p><i>Cassandra Wallace</i></p>
										<ul class="del dropotron">
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - Literature Review - WLLCAS004.pdf ">Literature Review</a></li>
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - U-SAM Final Paper - WLLCAS004.pdf">Project Paper</a></li>
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - U-SAM Code - WLLCAS004.zip">Code</a></li>
										</ul>
									</li>

									<li class="del dropdown">
										<p><strong>SAM-LoRA</strong></p>
										<p><i>Tapera Chikumbu</i></p>
										<ul class="del dropotron">
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - Literature Review - CHKTAP011.pdf">Literature Review</a></li>
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - SAMSeg-LoRA Final Paper - CHKTAP011.pdf">Project Paper</a></li>
											<li><a style="padding: 0px 15px" target="_blank" class="button primary icon solid fa-download" href="deliverables/SAMSeg - SAMSEG-LoRA Code - CHKTAP011.zip">Code</a></li>
										</ul>
									</li>
								</ul>
							</section>
						</div>

					</section>
					
				</section>

			<!-- Footer -->
				<footer id="footer">
					<div class="footer-content">
						<h3>&#129504; <strong>SAMSeg:</strong> Improving SAM for Brain Tumour Segmentation</h3>
						
						<!-- Authors and Supervisors in Two Columns -->
						<div class="author-supervisor-container">
							<div class="authors">
								<p><strong>Authors:</strong></p>
								<ul>
									<li>Tapera Chikumbu - <a href="mailto:chktap011@myuct.ac.za">chktap011@myuct.ac.za</a></li>
									<li>Cassandra Wallace - <a href="mailto:wllcas004@myuct.ac.za">wllcas004@myuct.ac.za</a></li>
								</ul>
							</div>
							
							<div class="supervisors">
								<p><strong>Supervisors:</strong></p>
								<ul>
									<li>Patrick Marais - <a href="mailto:patrick@cs.uct.ac.za">patrick@cs.uct.ac.za</a></li>
									<li>Fred Nicolls - <a href="mailto:fred.nicolls@uct.ac.za">fred.nicolls@uct.ac.za</a></li>
								</ul>
							</div>
						</div>
						
						<!-- UCT Crest Section -->
						<div class="uct-crest">
							<img src="images/uct_logo.png" alt="UCT Crest" style="width: 100px; height: auto;">
						</div>
						
						<!-- University Info -->
						<ul class="university-info">
							<li>&copy; 2024, University of Cape Town, Computer Science Department</li>
							<li>Rondebosch, Cape Town, 7701, South Africa</li>
							<li>All Rights Reserved.</li>
						</ul>

						<!-- Copyright and Design Credits -->
						<ul class="copyright">
							<li>Design by <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>